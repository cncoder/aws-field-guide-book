# AWS MSK Python å®¢æˆ·ç«¯è¿æ¥è§£å†³æ–¹æ¡ˆ

> ğŸ¯ **å¼€æºé¡¹ç›®**: è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„AWS MSK (Managed Streaming for Apache Kafka) Pythonå®¢æˆ·ç«¯è¿æ¥æ¼”ç¤ºé¡¹ç›®ï¼Œæ”¯æŒSASL/SCRAMå’ŒIAMä¸¤ç§è®¤è¯æ–¹å¼ã€‚
> 
> ğŸ“š **å¿«é€Ÿå¼€å§‹**: è¯·å‚é˜… [QUICKSTART.md](QUICKSTART.md) å¿«é€Ÿéƒ¨ç½²å’Œæµ‹è¯•ã€‚
> 
> âš ï¸ **æ³¨æ„**: ä½¿ç”¨å‰è¯·å¤åˆ¶é…ç½®æ¨¡æ¿æ–‡ä»¶å¹¶å¡«å…¥æ‚¨çš„å®é™…AWSèµ„æºä¿¡æ¯ã€‚


## ğŸ“‹ ç›®å½•

1. [è§£å†³æ–¹æ¡ˆæ¦‚è¿°](#è§£å†³æ–¹æ¡ˆæ¦‚è¿°)
2. [æ¶æ„è®¾è®¡](#æ¶æ„è®¾è®¡)
3. [è®¤è¯æ–¹å¼è¯¦è§£](#è®¤è¯æ–¹å¼è¯¦è§£)
4. [IAMæƒé™é…ç½®](#iamæƒé™é…ç½®)
5. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
6. [é™„å½•](#é™„å½•)

---

## è§£å†³æ–¹æ¡ˆæ¦‚è¿°

æœ¬è§£å†³æ–¹æ¡ˆæä¾›äº†ä¸€ä¸ªå®Œæ•´çš„AWS MSK (Managed Streaming for Apache Kafka) Pythonå®¢æˆ·ç«¯è¿æ¥å®ç°ï¼Œæ”¯æŒä¸¤ç§ä¸»è¦è®¤è¯æ–¹å¼ï¼š

### âœ… æ”¯æŒçš„è®¤è¯æ–¹å¼
1. **SASL/SCRAMè®¤è¯** - ç”¨æˆ·åå¯†ç è®¤è¯
2. **IAMè®¤è¯** - AWSèº«ä»½è®¤è¯ï¼ˆä¼ä¸šçº§ï¼‰

---

## æ¶æ„è®¾è®¡

### ç½‘ç»œæ¶æ„å›¾
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VPC: 10.50.0.0/16                           â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Private Subnet    â”‚         â”‚        MSK Cluster         â”‚ â”‚
â”‚  â”‚   10.50.128.0/20    â”‚         â”‚    (Multi-AZ Deployment)   â”‚ â”‚
â”‚  â”‚                     â”‚         â”‚                             â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚      EC2      â”‚  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  â”‚  Broker 1 (AZ-1a)      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚   t3.micro    â”‚  â”‚         â”‚  â”‚  Port 9096 (SCRAM)     â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  Python 3.8   â”‚  â”‚         â”‚  â”‚  Port 9098 (IAM)       â”‚ â”‚ â”‚
â”‚  â”‚  â”‚               â”‚  â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚                                  â”‚  â”‚  Broker 2 (AZ-1b)      â”‚ â”‚ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â”‚  Port 9096 (SCRAM)     â”‚ â”‚ â”‚
â”‚  â”‚   Secrets Manager   â”‚         â”‚  â”‚  Port 9098 (IAM)       â”‚ â”‚ â”‚
â”‚  â”‚   SCRAM Credentials â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç»„ä»¶è¯´æ˜
- **MSKé›†ç¾¤**: 2ä¸ªkafka.t3.smallå®ä¾‹ï¼Œè·¨AZéƒ¨ç½²
- **EC2å®¢æˆ·ç«¯**: t3.microå®ä¾‹ï¼ŒPython 3.8ç¯å¢ƒ
- **Secrets Manager**: å­˜å‚¨SCRAMè®¤è¯å‡­æ®
- **IAMè§’è‰²**: æä¾›å¿…è¦çš„AWSæœåŠ¡è®¿é—®æƒé™

---

## è®¤è¯æ–¹å¼è¯¦è§£

### ğŸ” æ–¹å¼ä¸€ï¼šSASL/SCRAMè®¤è¯

**é€‚ç”¨åœºæ™¯**: ä¼ ç»Ÿç”¨æˆ·åå¯†ç è®¤è¯æ–¹å¼

#### è®¤è¯æµç¨‹
1. EC2å®ä¾‹é€šè¿‡IAMè§’è‰²è®¿é—®Secrets Manager
2. ä»Secrets Managerè·å–SCRAMå‡­æ®ï¼ˆç”¨æˆ·å/å¯†ç ï¼‰
3. ä½¿ç”¨SCRAM-SHA-512æœºåˆ¶è¿æ¥MSKé›†ç¾¤
4. å»ºç«‹TLSåŠ å¯†è¿æ¥

#### é…ç½®ä¿¡æ¯
```bash
# è¿æ¥ç«¯ç‚¹
Bootstrap Servers: broker1:9096,broker2:9096

# è®¤è¯é…ç½®
SASL Mechanism: SCRAM-SHA-512
Security Protocol: SASL_SSL
Username: msk_user (å­˜å‚¨åœ¨Secrets Manager)
Password: [è‡ªåŠ¨ç”Ÿæˆ] (å­˜å‚¨åœ¨Secrets Manager)

# Secretåç§°
Secret Name: AmazonMSK_msk-poc-msk-scram-credentials
```

#### Pythonç¯å¢ƒè¦æ±‚

**ç³»ç»Ÿè¦æ±‚**
```bash
# Pythonç‰ˆæœ¬
Python >= 3.7

# å¿…éœ€çš„ç³»ç»ŸåŒ…
# Amazon Linux 2
sudo yum install -y gcc python3-devel librdkafka-devel

# Ubuntu/Debian
sudo apt-get install -y gcc python3-dev librdkafka-dev

# CentOS/RHEL
sudo yum install -y gcc python3-devel librdkafka-devel
```

**Pythonåº“ä¾èµ–**
```bash
# æ ¸å¿ƒåº“åŠç‰ˆæœ¬
confluent-kafka==1.9.2      # Kafkaå®¢æˆ·ç«¯åº“
boto3>=1.28.0               # AWS SDK
requests>=2.25.0            # HTTPè¯·æ±‚åº“

# å®‰è£…å‘½ä»¤
python3 -m pip install --user confluent-kafka==1.9.2 boto3 requests
```

**requirements.txtæ–‡ä»¶**
```txt
confluent-kafka==1.9.2
boto3>=1.28.0
requests>=2.25.0
botocore>=1.31.0
urllib3<2.0
```

#### AWSå®˜æ–¹æ–‡æ¡£å‚è€ƒ

**MSK SASL/SCRAMè®¤è¯è®¾ç½®**
- [Amazon MSK SASL/SCRAMèº«ä»½éªŒè¯](https://docs.aws.amazon.com/msk/latest/developerguide/msk-password.html)
- [ä½¿ç”¨AWS Secrets Managerç®¡ç†MSKå‡­æ®](https://docs.aws.amazon.com/msk/latest/developerguide/msk-password.html#msk-password-tutorial)
- [MSKé›†ç¾¤å®‰å…¨é…ç½®](https://docs.aws.amazon.com/msk/latest/developerguide/security.html)


#### ç¯å¢ƒå‡†å¤‡

**1. è¿æ¥åˆ°EC2å®ä¾‹**

æ–¹æ³•1: SSHè¿æ¥
```bash
# ä½¿ç”¨SSHå¯†é’¥è¿æ¥
ssh -i your-key.pem ec2-user@your-ec2-ip

# ä½¿ç”¨SSHä»£ç†è½¬å‘
ssh -A ec2-user@your-ec2-ip
```

æ–¹æ³•2: Session Managerè¿æ¥
```bash
# è·å–å®ä¾‹ID
INSTANCE_ID=$(aws ec2 describe-instances \
  --filters "Name=tag:Name,Values=msk-poc-ec2" \
  --query "Reservations[0].Instances[0].InstanceId" \
  --output text --region ap-southeast-1)

# é€šè¿‡Session Managerè¿æ¥
aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1
```

**2. ç¯å¢ƒå˜é‡è®¾ç½®**
```bash
# è¿›å…¥å·¥ä½œç›®å½•
cd /home/ec2-user/msk-poc

# åŠ è½½ç¯å¢ƒå˜é‡
source msk_config.env

# éªŒè¯ç¯å¢ƒå˜é‡
echo "SCRAM Bootstrap: $MSK_BOOTSTRAP_SERVERS_SCRAM"
echo "IAM Bootstrap: $MSK_BOOTSTRAP_SERVERS_IAM"
echo "Secret Name: $MSK_SCRAM_SECRET_NAME"
```

#### SCRAMç”Ÿäº§è€…ä»£ç  (producer_scram.py)
```python
#!/usr/bin/env python3
"""
AWS MSK SASL/SCRAM è®¤è¯ç”Ÿäº§è€…
æ”¯æŒä» Secrets Manager è·å–è®¤è¯å‡­æ®
"""

import os
import json
import time
import logging
from datetime import datetime
from confluent_kafka import Producer
import boto3
from botocore.exceptions import ClientError

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def get_secret_value(secret_name, region_name):
    """ä» AWS Secrets Manager è·å–å¯†é’¥å€¼"""
    session = boto3.session.Session()
    client = session.client(
        service_name='secretsmanager',
        region_name=region_name
    )
    
    try:
        get_secret_value_response = client.get_secret_value(SecretId=secret_name)
        secret = get_secret_value_response['SecretString']
        return json.loads(secret)
    except ClientError as e:
        logger.error(f"è·å–å¯†é’¥å¤±è´¥: {e}")
        raise e

def delivery_report(err, msg):
    """æ¶ˆæ¯ä¼ é€’å›è°ƒå‡½æ•°"""
    if err is not None:
        logger.error(f'æ¶ˆæ¯ä¼ é€’å¤±è´¥: {err}')
    else:
        logger.info(f'æ¶ˆæ¯ {msg.key().decode("utf-8")} å·²å‘é€åˆ° {msg.topic()} [{msg.partition()}] offset {msg.offset()}')

def create_producer():
    """åˆ›å»º SASL/SCRAM è®¤è¯çš„ Kafka ç”Ÿäº§è€…"""
    # ç¯å¢ƒå˜é‡
    bootstrap_servers = os.getenv('MSK_BOOTSTRAP_SERVERS_SCRAM')
    secret_name = os.getenv('MSK_SCRAM_SECRET_NAME', 'AmazonMSK_msk-poc-msk-scram-credentials')
    region = os.getenv('AWS_DEFAULT_REGION', 'ap-southeast-1')
    
    if not bootstrap_servers:
        raise ValueError("MSK_BOOTSTRAP_SERVERS_SCRAM ç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    logger.info("å¯åŠ¨å¸¦æœ‰SASL/SCRAMè®¤è¯çš„MSKç”Ÿäº§è€…")
    
    # è·å–SCRAMå‡­æ®
    try:
        credentials = get_secret_value(secret_name, region)
        username = credentials['username']
        password = credentials['password']
        logger.info(f"ç”¨æˆ·å: {username}")
    except Exception as e:
        logger.error(f"è·å–SCRAMå‡­æ®å¤±è´¥: {e}")
        raise
    
    # ç”Ÿäº§è€…é…ç½®
    producer_config = {
        'bootstrap.servers': bootstrap_servers,
        'security.protocol': 'SASL_SSL',
        'sasl.mechanism': 'SCRAM-SHA-512',
        'sasl.username': username,
        'sasl.password': password,
        'client.id': 'msk-scram-producer',
        'acks': 'all',
        'retries': 3,
        'retry.backoff.ms': 1000,
        'request.timeout.ms': 30000,
        'delivery.timeout.ms': 60000
    }
    
    try:
        producer = Producer(producer_config)
        logger.info("ä½¿ç”¨SASL/SCRAMè®¤è¯æˆåŠŸåˆ›å»ºç”Ÿäº§è€…")
        return producer
    except Exception as e:
        logger.error(f"åˆ›å»ºç”Ÿäº§è€…å¤±è´¥: {e}")
        raise

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºç”Ÿäº§è€…
        producer = create_producer()
        
        # é…ç½®å‚æ•°
        topic = os.getenv('MSK_TOPIC', 'msk-poc-topic')
        num_messages = int(os.getenv('NUM_MESSAGES', '5'))
        message_interval = int(os.getenv('MESSAGE_INTERVAL', '1'))
        
        logger.info(f"å¼€å§‹å‘é€ {num_messages} æ¡æ¶ˆæ¯åˆ°ä¸»é¢˜ '{topic}'")
        
        # å‘é€æ¶ˆæ¯
        for i in range(1, num_messages + 1):
            message_key = str(i)
            message_value = {
                'message_id': i,
                'timestamp': datetime.now().isoformat(),
                'content': f'SCRAMè®¤è¯æµ‹è¯•æ¶ˆæ¯ {i}',
                'producer': 'msk-scram-producer'
            }
            
            producer.produce(
                topic=topic,
                key=message_key,
                value=json.dumps(message_value, ensure_ascii=False),
                callback=delivery_report
            )
            
            # ç­‰å¾…æ¶ˆæ¯å‘é€
            producer.poll(0)
            
            if i < num_messages:
                time.sleep(message_interval)
        
        # ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ
        logger.info("ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ...")
        producer.flush(timeout=30)
        
        logger.info("æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ")
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise
    finally:
        if 'producer' in locals():
            producer.flush()

if __name__ == "__main__":
    main()
```

#### SCRAMæ¶ˆè´¹è€…ä»£ç  (consumer_scram.py)
```python
#!/usr/bin/env python3
"""
AWS MSK SASL/SCRAM è®¤è¯æ¶ˆè´¹è€…
æ”¯æŒä» Secrets Manager è·å–è®¤è¯å‡­æ®
"""

import os
import json
import logging
from confluent_kafka import Consumer, KafkaError
import boto3
from botocore.exceptions import ClientError

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def get_secret_value(secret_name, region_name):
    """ä» AWS Secrets Manager è·å–å¯†é’¥å€¼"""
    session = boto3.session.Session()
    client = session.client(
        service_name='secretsmanager',
        region_name=region_name
    )
    
    try:
        get_secret_value_response = client.get_secret_value(SecretId=secret_name)
        secret = get_secret_value_response['SecretString']
        return json.loads(secret)
    except ClientError as e:
        logger.error(f"è·å–å¯†é’¥å¤±è´¥: {e}")
        raise e

def create_consumer():
    """åˆ›å»º SASL/SCRAM è®¤è¯çš„ Kafka æ¶ˆè´¹è€…"""
    # ç¯å¢ƒå˜é‡
    bootstrap_servers = os.getenv('MSK_BOOTSTRAP_SERVERS_SCRAM')
    secret_name = os.getenv('MSK_SCRAM_SECRET_NAME', 'AmazonMSK_msk-poc-msk-scram-credentials')
    region = os.getenv('AWS_DEFAULT_REGION', 'ap-southeast-1')
    consumer_group = os.getenv('MSK_CONSUMER_GROUP', 'msk-scram-consumer-group')
    
    if not bootstrap_servers:
        raise ValueError("MSK_BOOTSTRAP_SERVERS_SCRAM ç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    logger.info("å¯åŠ¨å¸¦æœ‰SASL/SCRAMè®¤è¯çš„MSKæ¶ˆè´¹è€…")
    
    # è·å–SCRAMå‡­æ®
    try:
        credentials = get_secret_value(secret_name, region)
        username = credentials['username']
        password = credentials['password']
        logger.info(f"ç”¨æˆ·å: {username}")
    except Exception as e:
        logger.error(f"è·å–SCRAMå‡­æ®å¤±è´¥: {e}")
        raise
    
    # æ¶ˆè´¹è€…é…ç½®
    consumer_config = {
        'bootstrap.servers': bootstrap_servers,
        'security.protocol': 'SASL_SSL',
        'sasl.mechanism': 'SCRAM-SHA-512',
        'sasl.username': username,
        'sasl.password': password,
        'group.id': consumer_group,
        'client.id': 'msk-scram-consumer',
        'auto.offset.reset': 'earliest',
        'enable.auto.commit': True,
        'auto.commit.interval.ms': 5000,
        'session.timeout.ms': 30000,
        'heartbeat.interval.ms': 10000
    }
    
    try:
        consumer = Consumer(consumer_config)
        logger.info(f"ä½¿ç”¨SASL/SCRAMè®¤è¯æˆåŠŸåˆ›å»ºæ¶ˆè´¹è€…ï¼Œæ¶ˆè´¹è€…ç»„: {consumer_group}")
        return consumer
    except Exception as e:
        logger.error(f"åˆ›å»ºæ¶ˆè´¹è€…å¤±è´¥: {e}")
        raise

def main():
    """ä¸»å‡½æ•°"""
    consumer = None
    try:
        # åˆ›å»ºæ¶ˆè´¹è€…
        consumer = create_consumer()
        
        # é…ç½®å‚æ•°
        topic = os.getenv('MSK_TOPIC', 'msk-poc-topic')
        consume_timeout = int(os.getenv('CONSUME_TIMEOUT', '30'))
        
        # è®¢é˜…ä¸»é¢˜
        consumer.subscribe([topic])
        logger.info(f"å·²è®¢é˜…ä¸»é¢˜: {topic}")
        logger.info(f"å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯ï¼Œè¶…æ—¶æ—¶é—´: {consume_timeout}ç§’")
        
        message_count = 0
        
        # æ¶ˆè´¹æ¶ˆæ¯
        while True:
            msg = consumer.poll(timeout=consume_timeout)
            
            if msg is None:
                logger.info(f"åœ¨ {consume_timeout} ç§’å†…æœªæ”¶åˆ°æ¶ˆæ¯ï¼Œé€€å‡ºæ¶ˆè´¹")
                break
            
            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    logger.info(f"åˆ°è¾¾åˆ†åŒºæœ«å°¾: {msg.topic()} [{msg.partition()}] offset {msg.offset()}")
                else:
                    logger.error(f"æ¶ˆè´¹è€…é”™è¯¯: {msg.error()}")
                continue
            
            # å¤„ç†æ¶ˆæ¯
            message_count += 1
            try:
                key = msg.key().decode('utf-8') if msg.key() else None
                value = json.loads(msg.value().decode('utf-8'))
                
                logger.info(f"æ”¶åˆ°æ¶ˆæ¯ {message_count}:")
                logger.info(f"  ä¸»é¢˜: {msg.topic()}")
                logger.info(f"  åˆ†åŒº: {msg.partition()}")
                logger.info(f"  åç§»é‡: {msg.offset()}")
                logger.info(f"  é”®: {key}")
                logger.info(f"  å†…å®¹: {value}")
                logger.info("-" * 50)
                
            except json.JSONDecodeError:
                logger.warning(f"æ¶ˆæ¯ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {msg.value()}")
            except Exception as e:
                logger.error(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
        
        logger.info(f"æ¶ˆè´¹å®Œæˆï¼Œæ€»å…±å¤„ç†äº† {message_count} æ¡æ¶ˆæ¯")
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise
    finally:
        if consumer:
            consumer.close()
            logger.info("æ¶ˆè´¹è€…å·²å…³é—­")

if __name__ == "__main__":
    main()
```

#### ä½¿ç”¨æ–¹æ³•
```bash
# åŸºæœ¬ä½¿ç”¨
python3 producer_scram.py
python3 consumer_scram.py

# è‡ªå®šä¹‰å‚æ•°
export NUM_MESSAGES=10
export MESSAGE_INTERVAL=2
export CONSUME_TIMEOUT=60
export MSK_CONSUMER_GROUP=my-consumer-group
python3 producer_scram.py
python3 consumer_scram.py
```

### ğŸ”‘ æ–¹å¼äºŒï¼šIAMè®¤è¯ï¼ˆä¼ä¸šçº§ï¼‰

**é€‚ç”¨åœºæ™¯**: ä¼ä¸šç¯å¢ƒï¼Œéœ€è¦AWSèº«ä»½é›†æˆå’Œç»†ç²’åº¦æƒé™æ§åˆ¶

#### è®¤è¯æµç¨‹è¯¦è§£
1. **è·å–AWSå‡­æ®**: æ”¯æŒå¤šç§æ–¹å¼è·å–AWSå‡­æ®
2. **ç”Ÿæˆè®¤è¯ä»¤ç‰Œ**: ä½¿ç”¨AWS MSK IAM SASL Signerç”ŸæˆOAuthä»¤ç‰Œ
3. **å»ºç«‹è¿æ¥**: ä½¿ç”¨SASL_OAUTHBEARERæœºåˆ¶è¿æ¥MSKé›†ç¾¤
4. **TLSåŠ å¯†**: å»ºç«‹å®‰å…¨çš„TLSåŠ å¯†è¿æ¥

#### Pythonç¯å¢ƒè¦æ±‚

**ç³»ç»Ÿè¦æ±‚**
```bash
# Pythonç‰ˆæœ¬è¦æ±‚
Python >= 3.8  # aws-msk-iam-sasl-signer-pythonè¦æ±‚

# å¿…éœ€çš„ç³»ç»ŸåŒ…
# Amazon Linux 2
sudo yum install -y gcc python38-devel librdkafka-devel

# Ubuntu/Debian
sudo apt-get install -y gcc python3.8-dev librdkafka-dev

# CentOS/RHEL
sudo yum install -y gcc python38-devel librdkafka-devel
```

**Pythonåº“ä¾èµ–**
```bash
# æ ¸å¿ƒåº“åŠç‰ˆæœ¬
confluent-kafka==1.9.2                    # Kafkaå®¢æˆ·ç«¯åº“
boto3>=1.28.0                             # AWS SDK
aws-msk-iam-sasl-signer-python>=1.0.2     # MSK IAMè®¤è¯åº“
requests>=2.25.0                          # HTTPè¯·æ±‚åº“

# å®‰è£…å‘½ä»¤
python3.8 -m pip install --user confluent-kafka==1.9.2 boto3 aws-msk-iam-sasl-signer-python requests
```

**requirements.txtæ–‡ä»¶**
```txt
confluent-kafka==1.9.2
boto3>=1.28.0
aws-msk-iam-sasl-signer-python>=1.0.2
requests>=2.25.0
botocore>=1.31.0
urllib3<2.0
```

#### AWSå®˜æ–¹æ–‡æ¡£å‚è€ƒ

**MSK IAMè®¤è¯è®¾ç½®**
- [Amazon MSK IAMèº«ä»½éªŒè¯å’Œæˆæƒ](https://docs.aws.amazon.com/msk/latest/developerguide/iam-access-control.html)
- [MSK IAMè®¤è¯ç°åœ¨æ”¯æŒæ‰€æœ‰ç¼–ç¨‹è¯­è¨€](https://aws.amazon.com/cn/blogs/big-data/amazon-msk-iam-authentication-now-supports-all-programming-languages/)

**IAMç­–ç•¥å’Œæƒé™**
- [MSKé›†ç¾¤ç­–ç•¥ç¤ºä¾‹](https://docs.aws.amazon.com/msk/latest/developerguide/iam-access-control.html#kafka-actions)

**åº“å…¼å®¹æ€§è¯´æ˜**
- **confluent-kafka 1.9.2**: ç¨³å®šç‰ˆæœ¬ï¼Œä¸librdkafka 0.11.4å…¼å®¹
- **aws-msk-iam-sasl-signer-python**: éœ€è¦Python 3.8+ï¼Œæä¾›MSK IAMè®¤è¯ä»¤ç‰Œç”ŸæˆåŠŸèƒ½

#### AWSå‡­æ®è·å–æ–¹å¼

**æ–¹æ³•1: IAMè§’è‰²ï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰**
```bash
# EC2å®ä¾‹è‡ªåŠ¨ä½¿ç”¨é™„åŠ çš„IAMè§’è‰²
# æ— éœ€é¢å¤–é…ç½®ï¼Œè‡ªåŠ¨è·å–ä¸´æ—¶å‡­æ®
```

**æ–¹æ³•2: ç¯å¢ƒå˜é‡ï¼ˆå¼€å‘æµ‹è¯•ï¼‰**
```bash
export AWS_ACCESS_KEY_ID="your-access-key"
export AWS_SECRET_ACCESS_KEY="your-secret-key"
export AWS_DEFAULT_REGION="ap-southeast-1"
```

**æ–¹æ³•3: AWS CLIé…ç½®**
```bash
aws configure set aws_access_key_id your-access-key
aws configure set aws_secret_access_key your-secret-key
aws configure set default.region ap-southeast-1
```

**æ–¹æ³•4: ä»£ç ä¸­é…ç½®ï¼ˆä¸æ¨èç”Ÿäº§ç¯å¢ƒï¼‰**
```python
import boto3
session = boto3.Session(
    aws_access_key_id='your-access-key',
    aws_secret_access_key='your-secret-key',
    region_name='ap-southeast-1'
)
```

#### Pythonåº“å®ç°åŸç†
IAMè®¤è¯ä½¿ç”¨`aws-msk-iam-sasl-signer-python`åº“å®ç°OAuthä»¤ç‰Œç”Ÿæˆï¼š

```python
from aws_msk_iam_sasl_signer import MSKAuthTokenProvider

def oauth_cb(oauth_config):
    # åˆ›å»ºMSKè®¤è¯ä»¤ç‰Œæä¾›è€…
    auth_token_provider = MSKAuthTokenProvider(region='ap-southeast-1')
    
    # ç”Ÿæˆè®¤è¯ä»¤ç‰Œ
    token, expiry_ms = auth_token_provider.generate_auth_token(bootstrap_servers)
    
    # è®¾ç½®OAuthé…ç½®
    oauth_config.token = token
    oauth_config.principal = "msk-iam-user"
```

#### é…ç½®ä¿¡æ¯
```bash
# è¿æ¥ç«¯ç‚¹
Bootstrap Servers: broker1:9098,broker2:9098

# è®¤è¯é…ç½®
SASL Mechanism: OAUTHBEARER
Security Protocol: SASL_SSL
OAuth Provider: AWS MSK IAM
```

#### ç¯å¢ƒå‡†å¤‡

**1. è¿æ¥åˆ°EC2å®ä¾‹**

æ–¹æ³•1: SSHè¿æ¥
```bash
# ä½¿ç”¨SSHå¯†é’¥è¿æ¥
ssh -i your-key.pem ec2-user@your-ec2-ip

# ä½¿ç”¨SSHä»£ç†è½¬å‘
ssh -A ec2-user@your-ec2-ip
```

æ–¹æ³•2: Session Managerè¿æ¥
```bash
# è·å–å®ä¾‹ID
INSTANCE_ID=$(aws ec2 describe-instances \
  --filters "Name=tag:Name,Values=msk-poc-ec2" \
  --query "Reservations[0].Instances[0].InstanceId" \
  --output text --region ap-southeast-1)

# é€šè¿‡Session Managerè¿æ¥
aws ssm start-session --target $INSTANCE_ID --region ap-southeast-1
```

**2. ç¯å¢ƒå˜é‡è®¾ç½®**
```bash
# è¿›å…¥å·¥ä½œç›®å½•
cd /home/ec2-user/msk-poc

# åŠ è½½ç¯å¢ƒå˜é‡
source msk_config.env

# éªŒè¯ç¯å¢ƒå˜é‡
echo "SCRAM Bootstrap: $MSK_BOOTSTRAP_SERVERS_SCRAM"
echo "IAM Bootstrap: $MSK_BOOTSTRAP_SERVERS_IAM"
echo "Secret Name: $MSK_SCRAM_SECRET_NAME"
```

#### IAMç”Ÿäº§è€…ä»£ç  (producer_iam_production_fixed.py)
```python
#!/usr/bin/env python3
"""
AWS MSK IAM è®¤è¯ç”Ÿäº§è€… - ç”Ÿäº§ç‰ˆæœ¬
ä½¿ç”¨ aws-msk-iam-sasl-signer-python åº“è¿›è¡Œ IAM è®¤è¯
"""

import os
import json
import time
import logging
from datetime import datetime
from confluent_kafka import Producer
from aws_msk_iam_sasl_signer import MSKAuthTokenProvider

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def oauth_cb(oauth_config):
    """OAuthå›è°ƒå‡½æ•°ï¼Œç”¨äºç”ŸæˆMSK IAMè®¤è¯ä»¤ç‰Œ"""
    try:
        # è·å–ç¯å¢ƒå˜é‡
        region = os.getenv('AWS_DEFAULT_REGION', 'ap-southeast-1')
        bootstrap_servers = os.getenv('MSK_BOOTSTRAP_SERVERS_IAM')
        
        if not bootstrap_servers:
            raise ValueError("MSK_BOOTSTRAP_SERVERS_IAM ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        logger.info(f"ç”ŸæˆIAMè®¤è¯ä»¤ç‰Œï¼ŒåŒºåŸŸ: {region}")
        
        # åˆ›å»ºMSKè®¤è¯ä»¤ç‰Œæä¾›è€…
        auth_token_provider = MSKAuthTokenProvider(region=region)
        
        # ç”Ÿæˆè®¤è¯ä»¤ç‰Œ
        token, expiry_ms = auth_token_provider.generate_auth_token(bootstrap_servers)
        
        # è®¾ç½®OAuthé…ç½®
        oauth_config.token = token
        oauth_config.principal = "msk-iam-user"
        
        logger.info("IAMè®¤è¯ä»¤ç‰Œç”ŸæˆæˆåŠŸ")
        
    except Exception as e:
        logger.error(f"OAuthå›è°ƒå¤±è´¥: {e}")
        raise

def delivery_report(err, msg):
    """æ¶ˆæ¯ä¼ é€’å›è°ƒå‡½æ•°"""
    if err is not None:
        logger.error(f'æ¶ˆæ¯ä¼ é€’å¤±è´¥: {err}')
    else:
        logger.info(f'æ¶ˆæ¯ {msg.key().decode("utf-8")} å·²å‘é€åˆ° {msg.topic()} [{msg.partition()}] offset {msg.offset()}')

def create_producer():
    """åˆ›å»º IAM è®¤è¯çš„ Kafka ç”Ÿäº§è€…"""
    # ç¯å¢ƒå˜é‡
    bootstrap_servers = os.getenv('MSK_BOOTSTRAP_SERVERS_IAM')
    
    if not bootstrap_servers:
        raise ValueError("MSK_BOOTSTRAP_SERVERS_IAM ç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    logger.info("å¯åŠ¨å¸¦æœ‰IAMè®¤è¯çš„MSKç”Ÿäº§è€…")
    
    # ç”Ÿäº§è€…é…ç½®
    producer_config = {
        'bootstrap.servers': bootstrap_servers,
        'security.protocol': 'SASL_SSL',
        'sasl.mechanism': 'OAUTHBEARER',
        'oauth_cb': oauth_cb,
        'client.id': 'msk-iam-producer',
        'acks': 'all',
        'retries': 3,
        'retry.backoff.ms': 1000,
        'request.timeout.ms': 30000,
        'delivery.timeout.ms': 60000
    }
    
    try:
        producer = Producer(producer_config)
        logger.info("ä½¿ç”¨IAMè®¤è¯æˆåŠŸåˆ›å»ºç”Ÿäº§è€…")
        return producer
    except Exception as e:
        logger.error(f"åˆ›å»ºç”Ÿäº§è€…å¤±è´¥: {e}")
        raise

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºç”Ÿäº§è€…
        producer = create_producer()
        
        # é…ç½®å‚æ•°
        topic = os.getenv('MSK_TOPIC', 'msk-poc-topic')
        num_messages = int(os.getenv('NUM_MESSAGES', '5'))
        message_interval = int(os.getenv('MESSAGE_INTERVAL', '1'))
        
        logger.info(f"å¼€å§‹å‘é€ {num_messages} æ¡æ¶ˆæ¯åˆ°ä¸»é¢˜ '{topic}'")
        
        # å‘é€æ¶ˆæ¯
        for i in range(1, num_messages + 1):
            message_key = str(i)
            message_value = {
                'message_id': i,
                'timestamp': datetime.now().isoformat(),
                'content': f'IAMè®¤è¯æµ‹è¯•æ¶ˆæ¯ {i}',
                'producer': 'msk-iam-producer'
            }
            
            producer.produce(
                topic=topic,
                key=message_key,
                value=json.dumps(message_value, ensure_ascii=False),
                callback=delivery_report
            )
            
            # ç­‰å¾…æ¶ˆæ¯å‘é€
            producer.poll(0)
            
            if i < num_messages:
                time.sleep(message_interval)
        
        # ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ
        logger.info("ç­‰å¾…æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ...")
        producer.flush(timeout=30)
        
        logger.info("æ‰€æœ‰æ¶ˆæ¯å‘é€å®Œæˆ")
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise
    finally:
        if 'producer' in locals():
            producer.flush()

if __name__ == "__main__":
    main()
```

#### IAMæ¶ˆè´¹è€…ä»£ç  (consumer_iam_production.py)
```python
#!/usr/bin/env python3
"""
AWS MSK IAM è®¤è¯æ¶ˆè´¹è€… - ç”Ÿäº§ç‰ˆæœ¬
ä½¿ç”¨ aws-msk-iam-sasl-signer-python åº“è¿›è¡Œ IAM è®¤è¯
"""

import os
import json
import logging
from confluent_kafka import Consumer, KafkaError
from aws_msk_iam_sasl_signer import MSKAuthTokenProvider

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def oauth_cb(oauth_config):
    """OAuthå›è°ƒå‡½æ•°ï¼Œç”¨äºç”ŸæˆMSK IAMè®¤è¯ä»¤ç‰Œ"""
    try:
        # è·å–ç¯å¢ƒå˜é‡
        region = os.getenv('AWS_DEFAULT_REGION', 'ap-southeast-1')
        bootstrap_servers = os.getenv('MSK_BOOTSTRAP_SERVERS_IAM')
        
        if not bootstrap_servers:
            raise ValueError("MSK_BOOTSTRAP_SERVERS_IAM ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        
        logger.info(f"ç”ŸæˆIAMè®¤è¯ä»¤ç‰Œï¼ŒåŒºåŸŸ: {region}")
        
        # åˆ›å»ºMSKè®¤è¯ä»¤ç‰Œæä¾›è€…
        auth_token_provider = MSKAuthTokenProvider(region=region)
        
        # ç”Ÿæˆè®¤è¯ä»¤ç‰Œ
        token, expiry_ms = auth_token_provider.generate_auth_token(bootstrap_servers)
        
        # è®¾ç½®OAuthé…ç½®
        oauth_config.token = token
        oauth_config.principal = "msk-iam-user"
        
        logger.info("IAMè®¤è¯ä»¤ç‰Œç”ŸæˆæˆåŠŸ")
        
    except Exception as e:
        logger.error(f"OAuthå›è°ƒå¤±è´¥: {e}")
        raise

def create_consumer():
    """åˆ›å»º IAM è®¤è¯çš„ Kafka æ¶ˆè´¹è€…"""
    # ç¯å¢ƒå˜é‡
    bootstrap_servers = os.getenv('MSK_BOOTSTRAP_SERVERS_IAM')
    consumer_group = os.getenv('MSK_CONSUMER_GROUP', 'msk-iam-consumer-group')
    
    if not bootstrap_servers:
        raise ValueError("MSK_BOOTSTRAP_SERVERS_IAM ç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    logger.info("å¯åŠ¨å¸¦æœ‰IAMè®¤è¯çš„MSKæ¶ˆè´¹è€…")
    
    # æ¶ˆè´¹è€…é…ç½®
    consumer_config = {
        'bootstrap.servers': bootstrap_servers,
        'security.protocol': 'SASL_SSL',
        'sasl.mechanism': 'OAUTHBEARER',
        'oauth_cb': oauth_cb,
        'group.id': consumer_group,
        'client.id': 'msk-iam-consumer',
        'auto.offset.reset': 'earliest',
        'enable.auto.commit': True,
        'auto.commit.interval.ms': 5000,
        'session.timeout.ms': 30000,
        'heartbeat.interval.ms': 10000
    }
    
    try:
        consumer = Consumer(consumer_config)
        logger.info(f"ä½¿ç”¨IAMè®¤è¯æˆåŠŸåˆ›å»ºæ¶ˆè´¹è€…ï¼Œæ¶ˆè´¹è€…ç»„: {consumer_group}")
        return consumer
    except Exception as e:
        logger.error(f"åˆ›å»ºæ¶ˆè´¹è€…å¤±è´¥: {e}")
        raise

def main():
    """ä¸»å‡½æ•°"""
    consumer = None
    try:
        # åˆ›å»ºæ¶ˆè´¹è€…
        consumer = create_consumer()
        
        # é…ç½®å‚æ•°
        topic = os.getenv('MSK_TOPIC', 'msk-poc-topic')
        consume_timeout = int(os.getenv('CONSUME_TIMEOUT', '30'))
        
        # è®¢é˜…ä¸»é¢˜
        consumer.subscribe([topic])
        logger.info(f"å·²è®¢é˜…ä¸»é¢˜: {topic}")
        logger.info(f"å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯ï¼Œè¶…æ—¶æ—¶é—´: {consume_timeout}ç§’")
        
        message_count = 0
        
        # æ¶ˆè´¹æ¶ˆæ¯
        while True:
            msg = consumer.poll(timeout=consume_timeout)
            
            if msg is None:
                logger.info(f"åœ¨ {consume_timeout} ç§’å†…æœªæ”¶åˆ°æ¶ˆæ¯ï¼Œé€€å‡ºæ¶ˆè´¹")
                break
            
            if msg.error():
                if msg.error().code() == KafkaError._PARTITION_EOF:
                    logger.info(f"åˆ°è¾¾åˆ†åŒºæœ«å°¾: {msg.topic()} [{msg.partition()}] offset {msg.offset()}")
                else:
                    logger.error(f"æ¶ˆè´¹è€…é”™è¯¯: {msg.error()}")
                continue
            
            # å¤„ç†æ¶ˆæ¯
            message_count += 1
            try:
                key = msg.key().decode('utf-8') if msg.key() else None
                value = json.loads(msg.value().decode('utf-8'))
                
                logger.info(f"æ”¶åˆ°æ¶ˆæ¯ {message_count}:")
                logger.info(f"  ä¸»é¢˜: {msg.topic()}")
                logger.info(f"  åˆ†åŒº: {msg.partition()}")
                logger.info(f"  åç§»é‡: {msg.offset()}")
                logger.info(f"  é”®: {key}")
                logger.info(f"  å†…å®¹: {value}")
                logger.info("-" * 50)
                
            except json.JSONDecodeError:
                logger.warning(f"æ¶ˆæ¯ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼: {msg.value()}")
            except Exception as e:
                logger.error(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
        
        logger.info(f"æ¶ˆè´¹å®Œæˆï¼Œæ€»å…±å¤„ç†äº† {message_count} æ¡æ¶ˆæ¯")
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise
    finally:
        if consumer:
            consumer.close()
            logger.info("æ¶ˆè´¹è€…å·²å…³é—­")

if __name__ == "__main__":
    main()
```

#### ä½¿ç”¨æ–¹æ³•
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export MSK_BOOTSTRAP_SERVERS_IAM="broker1:9098,broker2:9098"
export AWS_DEFAULT_REGION="ap-southeast-1"
export MSK_TOPIC="msk-poc-topic"

# åŸºæœ¬ä½¿ç”¨
python3.8 producer_iam_production_fixed.py
python3.8 consumer_iam_production.py

# è‡ªå®šä¹‰é…ç½®
export NUM_MESSAGES=5
export MESSAGE_INTERVAL=1
export CONSUME_TIMEOUT=30
python3.8 producer_iam_production_fixed.py
python3.8 consumer_iam_production.py
```

## IAMæƒé™é…ç½®

### EC2å®ä¾‹IAMè§’è‰²æƒé™

#### å¿…éœ€çš„IAMç­–ç•¥
```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:Connect",
                "kafka-cluster:AlterCluster",
                "kafka-cluster:DescribeCluster"
            ],
            "Resource": "arn:aws:kafka:ap-southeast-1:*:cluster/msk-poc-cluster/*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:*Topic*",
                "kafka-cluster:WriteData",
                "kafka-cluster:ReadData"
            ],
            "Resource": "arn:aws:kafka:ap-southeast-1:*:topic/msk-poc-cluster/*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:AlterGroup",
                "kafka-cluster:DescribeGroup"
            ],
            "Resource": "arn:aws:kafka:ap-southeast-1:*:group/msk-poc-cluster/*"
        }
    ]
}
```

#### Secrets Managerè®¿é—®æƒé™
```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "secretsmanager:GetSecretValue",
                "secretsmanager:DescribeSecret"
            ],
            "Resource": "arn:aws:secretsmanager:ap-southeast-1:*:secret:AmazonMSK_*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "kms:Decrypt"
            ],
            "Resource": "arn:aws:kms:ap-southeast-1:*:key/*",
            "Condition": {
                "StringEquals": {
                    "kms:ViaService": "secretsmanager.ap-southeast-1.amazonaws.com"
                }
            }
        }
    ]
}
```

### Access Keyæƒé™é…ç½®

#### æœ€å°æƒé™åŸåˆ™
```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "kafka-cluster:Connect",
                "kafka-cluster:WriteData",
                "kafka-cluster:ReadData",
                "kafka-cluster:CreateTopic",
                "kafka-cluster:DescribeTopic"
            ],
            "Resource": [
                "arn:aws:kafka:ap-southeast-1:*:cluster/msk-poc-cluster/*",
                "arn:aws:kafka:ap-southeast-1:*:topic/msk-poc-cluster/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "secretsmanager:GetSecretValue"
            ],
            "Resource": "arn:aws:secretsmanager:ap-southeast-1:*:secret:AmazonMSK_*"
        }
    ]
}
```

---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. è¿æ¥è¶…æ—¶é—®é¢˜
**ç—‡çŠ¶**: `Connection timeout` æˆ– `Network unreachable`
```bash
# æ£€æŸ¥å®‰å…¨ç»„é…ç½®
aws ec2 describe-security-groups --group-ids sg-xxx --region ap-southeast-1

# æ£€æŸ¥MSKé›†ç¾¤çŠ¶æ€
aws kafka describe-cluster --cluster-arn arn:aws:kafka:... --region ap-southeast-1

# æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
telnet broker-host 9096
```

#### 2. SCRAMè®¤è¯å¤±è´¥
**ç—‡çŠ¶**: `Authentication failed` æˆ– `Invalid credentials`
```bash
# æ£€æŸ¥å¯†é’¥çŠ¶æ€
aws secretsmanager describe-secret \
  --secret-id AmazonMSK_msk-poc-msk-scram-credentials \
  --region ap-southeast-1

# æ£€æŸ¥å¯†é’¥å…³è”çŠ¶æ€
aws kafka describe-cluster --cluster-arn arn:aws:kafka:... \
  --region ap-southeast-1 | grep -i scram

# éªŒè¯IAMæƒé™
aws sts get-caller-identity
```

#### 3. IAMè®¤è¯é—®é¢˜
**ç—‡çŠ¶**: `Token generation failed` æˆ– `OAuth callback failed`
```bash
# æ£€æŸ¥IAMè§’è‰²
aws sts assume-role --role-arn arn:aws:iam::...:role/msk-poc-ec2-msk-role \
  --role-session-name test

# æ£€æŸ¥Pythonåº“ç‰ˆæœ¬
python3.8 -c "from aws_msk_iam_sasl_signer import MSKAuthTokenProvider; print('OK')"

# æ£€æŸ¥ç½‘ç»œæ—¶é—´åŒæ­¥
sudo chrony sources -v
```

#### 4. PythonåŒ…é—®é¢˜
**ç—‡çŠ¶**: `ModuleNotFoundError` æˆ– `Import Error`
```bash
# é‡æ–°å®‰è£…åŒ…
python3.8 -m pip install --user --upgrade confluent-kafka boto3 aws-msk-iam-sasl-signer-python

# æ£€æŸ¥åŒ…ç‰ˆæœ¬
python3.8 -m pip list --user | grep -E "(confluent|boto3|aws-msk)"

# æ£€æŸ¥Pythonè·¯å¾„
python3.8 -c "import sys; print(sys.path)"
```

### æ—¥å¿—æŸ¥çœ‹

#### åº”ç”¨æ—¥å¿—
```bash
# Pythonè„šæœ¬æ—¥å¿—è¾“å‡ºåˆ°stderr
python3 producer_scram.py 2>&1 | tee producer.log

# æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
export PYTHONPATH=/home/ec2-user/.local/lib/python3.8/site-packages
python3.8 -v producer_iam_production_fixed.py
```

#### MSKé›†ç¾¤æ—¥å¿—
```bash
# æŸ¥çœ‹CloudWatchæ—¥å¿—ç»„
aws logs describe-log-groups --log-group-name-prefix "/aws/msk" --region ap-southeast-1

# æŸ¥çœ‹å…·ä½“æ—¥å¿—æµ
aws logs describe-log-streams --log-group-name "/aws/msk/msk-poc-cluster" --region ap-southeast-1
```

---



---

## é™„å½•

### A. EC2å®ä¾‹é…ç½®è¯¦æƒ…

#### å®ä¾‹è§„æ ¼
```yaml
å®ä¾‹ç±»å‹: t3.micro
vCPU: 2
å†…å­˜: 1 GiB
ç½‘ç»œæ€§èƒ½: æœ€é«˜5 Gigabit
EBSä¼˜åŒ–: é»˜è®¤å¯ç”¨
å­˜å‚¨: 20 GB gp3
```

#### æ“ä½œç³»ç»Ÿé…ç½®
```bash
æ“ä½œç³»ç»Ÿ: Amazon Linux 2
å†…æ ¸ç‰ˆæœ¬: 5.10.x
Pythonç‰ˆæœ¬: 3.7.16 (é»˜è®¤), 3.8.20 (å·²å®‰è£…)
åŒ…ç®¡ç†å™¨: yum, pip3
```

#### å®‰è£…çš„è½¯ä»¶åŒ…
```bash
# ç³»ç»ŸåŒ…
gcc-7.3.1
python38-3.8.20
python38-devel-3.8.20
librdkafka-devel-0.11.4

# PythonåŒ…
confluent-kafka==1.9.2
boto3==1.37.38
aws-msk-iam-sasl-signer-python==1.0.2
requests==2.32.4
```

#### ç½‘ç»œé…ç½®
```yaml
VPC: vpc-052b2576f1eee33cd
å­ç½‘: ç§æœ‰å­ç½‘ (10.50.128.0/20)
å®‰å…¨ç»„: 
  - å‡ºç«™: å…¨éƒ¨å…è®¸
  - å…¥ç«™: ä»…SSM Session Manager
å¼¹æ€§IP: æ— ï¼ˆç§æœ‰å®ä¾‹ï¼‰
```

### B. MSKé›†ç¾¤é…ç½®è¯¦æƒ…

#### é›†ç¾¤è§„æ ¼
```yaml
é›†ç¾¤åç§°: msk-poc-cluster
Kafkaç‰ˆæœ¬: 2.8.1
å®ä¾‹ç±»å‹: kafka.t3.small
å®ä¾‹æ•°é‡: 2
å¯ç”¨åŒº: ap-southeast-1a, ap-southeast-1b
```

#### å­˜å‚¨é…ç½®
```yaml
å­˜å‚¨ç±»å‹: EBS gp3
æ¯ä¸ªä»£ç†å­˜å‚¨: 100 GB
åŠ å¯†: å¯ç”¨ (AWS KMS)
```

#### ç½‘ç»œé…ç½®
```yaml
VPC: vpc-052b2576f1eee33cd
å­ç½‘: 
  - subnet-xxx (ap-southeast-1a)
  - subnet-yyy (ap-southeast-1b)
å®‰å…¨ç»„: msk-poc-msk-sg
```

#### è®¤è¯é…ç½®
```yaml
TLSåŠ å¯†: å¯ç”¨
SASL/SCRAM: å¯ç”¨
  - ç”¨æˆ·å: msk_user
  - å¯†ç : å­˜å‚¨åœ¨Secrets Manager
IAMè®¤è¯: å¯ç”¨
  - ç«¯å£: 9098
  - æœºåˆ¶: SASL_OAUTHBEARER
```

#### ç›‘æ§é…ç½®
```yaml
CloudWatchç›‘æ§: åŸºç¡€ç›‘æ§
JMXå¯¼å‡ºå™¨: å¯ç”¨
Prometheusç›‘æ§: å¯é€‰
æ—¥å¿—ä¼ è¾“: CloudWatch Logs
```

### C. ç½‘ç»œç«¯å£è¯´æ˜

#### MSKé›†ç¾¤ç«¯å£
```
9092: PLAINTEXT (æœªå¯ç”¨)
9094: TLS (å®¢æˆ·ç«¯åˆ°ä»£ç†)
9096: SASL_SSL (SCRAMè®¤è¯)
9098: SASL_SSL (IAMè®¤è¯)
2181: Zookeeper (å†…éƒ¨ä½¿ç”¨)
```

#### å®‰å…¨ç»„è§„åˆ™
```yaml
MSKå®‰å…¨ç»„ (å…¥ç«™):
  - ç«¯å£ 9094: æ¥æº EC2å®‰å…¨ç»„
  - ç«¯å£ 9096: æ¥æº EC2å®‰å…¨ç»„  
  - ç«¯å£ 9098: æ¥æº EC2å®‰å…¨ç»„
  - ç«¯å£ 2181: æ¥æº EC2å®‰å…¨ç»„

EC2å®‰å…¨ç»„ (å‡ºç«™):
  - å…¨éƒ¨ç«¯å£: ç›®æ ‡ 0.0.0.0/0
```

### D. ç¯å¢ƒå˜é‡å®Œæ•´åˆ—è¡¨

#### MSKè¿æ¥é…ç½®
```bash
MSK_CLUSTER_ARN="arn:aws:kafka:ap-southeast-1:xxx:cluster/msk-poc-cluster/xxx"
MSK_CLUSTER_NAME="msk-poc-cluster"
MSK_BOOTSTRAP_SERVERS_IAM="broker1:9098,broker2:9098"
MSK_BOOTSTRAP_SERVERS_SCRAM="broker1:9096,broker2:9096"
MSK_BOOTSTRAP_SERVERS_TLS="broker1:9094,broker2:9094"
MSK_ZOOKEEPER_CONNECT="zk1:2181,zk2:2181,zk3:2181"
```

#### è®¤è¯é…ç½®
```bash
MSK_SCRAM_SECRET_ARN="arn:aws:secretsmanager:ap-southeast-1:xxx:secret:xxx"
MSK_SCRAM_SECRET_NAME="AmazonMSK_msk-poc-msk-scram-credentials"
```

#### EC2é…ç½®
```bash
EC2_INSTANCE_ID="i-xxxxxxxxxxxxxxxxx"
EC2_PRIVATE_IP="10.x.x.x"
```

#### AWSé…ç½®
```bash
AWS_DEFAULT_REGION="ap-southeast-1"
AWS_REGION="ap-southeast-1"
```

### E. Terraforméƒ¨ç½²æŒ‡å—

#### å‰ç½®è¦æ±‚
ç¡®ä¿éƒ¨ç½²è´¦æˆ·å…·æœ‰ä»¥ä¸‹æƒé™ï¼š
- EC2: åˆ›å»ºå®ä¾‹ã€å®‰å…¨ç»„ã€å¯†é’¥å¯¹
- MSK: åˆ›å»ºé›†ç¾¤ã€é…ç½®è®¤è¯
- IAM: åˆ›å»ºè§’è‰²ã€ç­–ç•¥ã€å®ä¾‹é…ç½®æ–‡ä»¶
- Secrets Manager: åˆ›å»ºå’Œç®¡ç†å¯†é’¥
- KMS: åˆ›å»ºå’Œä½¿ç”¨åŠ å¯†å¯†é’¥
- CloudWatch: åˆ›å»ºæ—¥å¿—ç»„
- SSM: Session Managerè®¿é—®

#### éƒ¨ç½²æ­¥éª¤
```bash
cd terraform

# åˆå§‹åŒ–Terraform
terraform init

# æŸ¥çœ‹éƒ¨ç½²è®¡åˆ’
terraform plan

# æ‰§è¡Œéƒ¨ç½²ï¼ˆçº¦30-40åˆ†é’Ÿï¼‰
terraform apply

# ç¡®è®¤éƒ¨ç½²
# è¾“å…¥ 'yes' ç¡®è®¤
```

#### éªŒè¯éƒ¨ç½²
```bash
# æ£€æŸ¥MSKé›†ç¾¤çŠ¶æ€
aws kafka describe-cluster --cluster-arn $(terraform output -raw msk_cluster_arn) --region ap-southeast-1

# æ£€æŸ¥EC2å®ä¾‹çŠ¶æ€
aws ec2 describe-instances --instance-ids $(terraform output -raw ec2_instance_id) --region ap-southeast-1

# æ£€æŸ¥Secrets Managerå¯†é’¥
aws secretsmanager describe-secret --secret-id $(terraform output -raw scram_secret_name) --region ap-southeast-1
```

#### è‡ªåŠ¨ç”Ÿæˆé…ç½®æ–‡ä»¶
éƒ¨ç½²å®Œæˆåï¼Œä½¿ç”¨è„šæœ¬è‡ªåŠ¨ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼š

```bash
# è¿”å›é¡¹ç›®æ ¹ç›®å½•
cd ..

# è‡ªåŠ¨ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰
./scripts/generate_config.sh

# æˆ–è€…ä»JSONè¾“å‡ºç”Ÿæˆ
cd terraform
terraform output -json > ../terraform_outputs.json
cd ..
./scripts/parse_terraform_outputs.sh

# éªŒè¯ç”Ÿæˆçš„é…ç½®
./verify_config.sh

# åŠ è½½é…ç½®å¹¶æµ‹è¯•
source msk_config.env
python3 python-clients/producer_scram.py
```
